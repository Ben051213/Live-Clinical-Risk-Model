# -*- coding: utf-8 -*-
"""DSS

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1AppSqEmyYPaj25DulDa1_GCa60edpj76
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelEncoder, label_binarize
from itertools import cycle

print("--- PHASE 1: DATA VISUALIZATION ---")

# Load the dataset
try:
    df = pd.read_csv('Health_Risk_Dataset.csv')
    print("Dataset 'Health_Risk_Dataset.csv' loaded successfully.")
except FileNotFoundError:
    print("ERROR: 'Health_Risk_Dataset.csv' not found. Please upload it to your Colab environment.")
    exit()
except Exception as e:
    print(f"An error occurred: {e}")
    exit()

sns.set(style="whitegrid", context="talk")

# Plot 1: Risk Level Distribution
plt.figure(figsize=(12, 7))
sns.countplot(x='Risk_Level', data=df, order=['Normal', 'Low', 'Medium', 'High'], palette="viridis")
plt.title('Distribution of Patient Risk Levels')
plt.savefig('risk_level_distribution.png')
print("Saved 'risk_level_distribution.png'")

# Plot 2: Vital Boxplots
vital_signs = ['Respiratory_Rate', 'Oxygen_Saturation', 'Systolic_BP', 'Heart_Rate', 'Temperature']
for vital in vital_signs:
    plt.figure(figsize=(12, 7))
    sns.boxplot(x='Risk_Level', y=vital, data=df, order=['Normal', 'Low', 'Medium', 'High'], palette="coolwarm")
    plt.title(f'{vital} by Health Risk Level')
    plt.savefig(f'{vital}_boxplot.png')
    print(f"Saved '{vital}_boxplot.png'")

print("\n--- PHASE 2: MODEL TRAINING & RULE EXPORT ---")

# --- Part A: The "Proof of Concept" Model (Random Forest) ---
print("\nTraining 'Proof of Concept' RandomForest Model...")

y = df['Risk_Level']
features_df = df.drop(columns=['Patient_ID', 'Risk_Level'])
X_processed = pd.get_dummies(features_df, columns=['Consciousness'], drop_first=True)

# Define our two label-ordering lists
# 1. This is the model's *actual* alphabetical order. We MUST use this for the ROC calculation.
model_class_order = sorted(y.unique())
print(f"Model's internal alphabetical order (for ROC): {model_class_order}")

# 2. This is our *logical* order for presentation slides.
presentation_order = ['High', 'Medium', 'Low', 'Normal']
print(f"Our logical presentation order (for Matrix/Report): {presentation_order}")


# Split data
X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.3, random_state=42, stratify=y)

# Train the "Pro" RandomForest
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Evaluate it
y_pred_rf = rf_model.predict(X_test)
y_prob_rf = rf_model.predict_proba(X_test) # Probabilities for ROC

accuracy = accuracy_score(y_test, y_pred_rf)
print(f"\n--- 'Proof of Concept' Model Accuracy: {accuracy * 100:.2f}% ---")

print("\nClassification Report (in logical presentation order):")
# Use our new 'presentation_order' for the report
print(classification_report(y_test, y_pred_rf, labels=presentation_order))

# --- Part B: Feature Importance (The "Weightage") ---
print("\n--- 'Proof of Concept' Model Feature Importance ---")
importances = rf_model.feature_importances_
feature_names_rf = X_processed.columns.tolist()
feature_df = pd.DataFrame({'Feature': feature_names_rf, 'Importance': importances})
feature_df = feature_df.sort_values(by='Importance', ascending=False)
plt.figure(figsize=(12, 8))
sns.barplot(x='Importance', y='Feature', data=feature_df, palette='viridis')
plt.title('Feature Importance: Which Vitals Predict Risk?')
plt.savefig('feature_importance.png')
print("Saved 'feature_importance.png'")


# --- Part C: Confusion Matrix (The "Pro" Error Analysis) ---
print("\n--- 'Proof of Concept' Model Error Analysis (Confusion Matrix) ---")
# Use our 'presentation_order' for the matrix labels
cm = confusion_matrix(y_test, y_pred_rf, labels=presentation_order)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=presentation_order)
fig, ax = plt.subplots(figsize=(10, 8))
disp.plot(ax=ax, cmap='Blues', colorbar=False)
ax.set_title('Confusion Matrix (in Logical Risk Order)')
plt.savefig('confusion_matrix.png')
print("Saved 'confusion_matrix.png'")


# --- Part D: ROC Curve and AUC (The "Pro" Performance Metric) ---
print("\n--- 'Proof of Concept' Model ROC-AUC Analysis ---")
# We still MUST use the model's internal order for the binarized labels
y_test_binarized = label_binarize(y_test, classes=model_class_order)
n_classes = y_test_binarized.shape[1]

plt.figure(figsize=(10, 8))

# --- (MODIFIED!) Create a color map and loop in presentation order ---
# 1. Define colors for our logical presentation order
color_map = {
    'High': 'red',
    'Medium': 'orange',
    'Low': 'blue',
    'Normal': 'green'
}

# 2. Loop in PRESENTATION order (High, Medium, Low, Normal)
for class_name in presentation_order:
    # 3. Find the *actual* index of this class in the model's alphabetical order
    # e.g., for 'Medium', index will be 2
    i = model_class_order.index(class_name)

    # 4. Get the correct data using that index
    y_true_class = y_test_binarized[:, i]
    y_prob_class = y_prob_rf[:, i]
    color = color_map[class_name]

    # Calculate ROC curve and AUC (This is still mathematically correct)
    fpr, tpr, _ = roc_curve(y_true_class, y_prob_class)
    roc_auc = auc(fpr, tpr)

    # 5. Plot this class's curve. The legend will now be in logical order.
    plt.plot(fpr, tpr, color=color, lw=2,
             label=f'ROC for "{class_name}" (AUC = {roc_auc:0.3f})')

# Add the "random guess" line
plt.plot([0, 1], [0, 1], 'k--', lw=2, label='Random Guess (AUC = 0.5)')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Multi-Class "One-vs-Rest" ROC Curves (in Logical Order)')
plt.legend(loc="lower right")
plt.savefig('roc_curves.png')
print("Saved 'roc_curves.png'")


# --- Part E: The "Deployment" Model (Decision Tree) ---
# these are the stuffs that is going to be in the website
print("\n--- Training 'Deployment' Decision Tree Model ---")
features_df_tree = df.drop(columns=['Patient_ID', 'Risk_Level'])
consc_encoder = LabelEncoder()
features_df_tree['Consciousness'] = consc_encoder.fit_transform(features_df_tree['Consciousness'])
X_tree = features_df_tree
y_tree = df['Risk_Level']
feature_names = X_tree.columns.tolist()
tree_model = DecisionTreeClassifier(max_depth=5, random_state=42)
tree_model.fit(X_tree, y_tree)

print("\n--- MODEL EXPORT: This is the logic for the website ---")
rules = export_text(tree_model, feature_names=feature_names)
print(rules)
print("\n--- SCRIPT COMPLETE ---")